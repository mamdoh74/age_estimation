{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project_test.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mamdoh74/age_estimation/blob/main/project_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epJ49xC3wLWh",
        "outputId": "f4827af4-ada6-46dc-eb1d-1cecc422b263"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lanfa\n"
          ]
        }
      ],
      "source": [
        "print(\"lanfa\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import time\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "4R7Kzfx1zv93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "cap.set(3, 480)  # set width\n",
        "cap.set(4, 640)  # set height"
      ],
      "metadata": {
        "id": "MPgiPuf42W2K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65f279ed-9136-4480-bf0c-5d0e090df19d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
        "age_list = ['(0, 2)', '(4, 6)', '(8, 12)', '(15, 20)', '(25, 32)', '(38, 43)', '(48, 53)', '(60, 100)']\n",
        "gender_list = ['Male', 'Female']"
      ],
      "metadata": {
        "id": "3PcJwYvFgpfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ofBy7IWPjW1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_caffe_models():\n",
        "    age_net = cv2.dnn.readNetFromCaffe(\n",
        "        'deploy_age.prototxt',\n",
        "        'age_net.caffemodel')\n",
        "\n",
        "    gender_net = cv2.dnn.readNetFromCaffe(\n",
        "        'deploy_gender.prototxt',\n",
        "        'gender_net.caffemodel')\n",
        "\n",
        "    return (age_net, gender_net)\n"
      ],
      "metadata": {
        "id": "5rhQ_egvgufH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_from_camera(age_net, gender_net):\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "\n",
        "    while True:\n",
        "\n",
        "        ret, image = cap.read()\n",
        "\n",
        "        face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
        "\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
        "\n",
        "        if (len(faces) > 0):\n",
        "            print(\"Found {} faces\".format(str(len(faces))))\n",
        "\n",
        "        for (x, y, w, h) in faces:\n",
        "            cv2.rectangle(image, (x, y), (x + w, y + h), (255, 255, 0), 2)\n",
        "\n",
        "            # Get Face\n",
        "            face_img = image[y:y + h, h:h + w].copy()\n",
        "            blob = cv2.dnn.blobFromImage(face_img, 1, (227, 227), MODEL_MEAN_VALUES, swapRB=False)\n",
        "\n",
        "            # Predict Gender\n",
        "            gender_net.setInput(blob)\n",
        "            gender_preds = gender_net.forward()\n",
        "            gender = gender_list[gender_preds[0].argmax()]\n",
        "            print(\"Gender : \" + gender)\n",
        "\n",
        "            # Predict Age\n",
        "            age_net.setInput(blob)\n",
        "            age_preds = age_net.forward()\n",
        "            age = age_list[age_preds[0].argmax()]\n",
        "            print(\"Age Range: \" + age)\n",
        "\n",
        "            overlay_text = \"%s %s\" % (gender, age)\n",
        "            cv2.putText(image, overlay_text, (x, y), font, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
        "\n",
        "        cv2.imshow('frame', image)\n",
        "\n",
        "        cv2.waitKey(0)\n",
        "            \n",
        "        cv2.destroyAllWindows()\n",
        "\n"
      ],
      "metadata": {
        "id": "1pYdmmDggwo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    age_net, gender_net = initialize_caffe_models()\n",
        "\n",
        "    read_from_camera(age_net, gender_net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "2qEFD0sVgzCn",
        "outputId": "83d7a84a-1748-404b-9515-f54c1fca21a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-4283163c9063>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mage_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender_net\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_caffe_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mread_from_camera\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-f87e3e279a2f>\u001b[0m in \u001b[0;36minitialize_caffe_models\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     age_net = cv2.dnn.readNetFromCaffe(\n\u001b[1;32m      3\u001b[0m         \u001b[0;34m'deploy_age.prototxt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         'age_net.caffemodel')\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     gender_net = cv2.dnn.readNetFromCaffe(\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/dnn/src/caffe/caffe_io.cpp:1121: error: (-2:Unspecified error) FAILED: fs.is_open(). Can't open \"deploy_age.prototxt\" in function 'ReadProtoFromTextFile'\n"
          ]
        }
      ]
    }
  ]
}